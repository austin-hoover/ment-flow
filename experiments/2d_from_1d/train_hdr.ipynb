{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375c80d1-a744-4207-83d3-99c3cdf7231f",
   "metadata": {},
   "source": [
    "## Train MENT-Flow without samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c0f06-6e78-438d-ad5c-3282226877b1",
   "metadata": {},
   "source": [
    "This notebook will illustrate an alternative way to train MENT-Flow. Instead of generating samples, we can numerically integrate the model probablity density to generate the predicted profiles. This requires an invertible lattice. It should dramatically improve the dynamic range of the generated profiles without requiring a huge number of particles. (We'll still need to generate samples to estimate the entropy.)\n",
    "\n",
    "This notebook is old and does not work currently. To do: update and convert to script `train_hdr.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cff34e-f8c9-4963-8aa7-cfb5bd474956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mentflow as mf\n",
    "import numpy as np\n",
    "import proplot as pplt\n",
    "import torch\n",
    "import zuko\n",
    "from torch.distributions.utils import _sum_rightmost\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotting\n",
    "import utils\n",
    "from data import gen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651a609-378d-4f85-9ae1-d4e8cfc1776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pplt.rc[\"cmap.discrete\"] = False\n",
    "pplt.rc[\"cmap.sequential\"] = \"viridis\"\n",
    "pplt.rc[\"figure.facecolor\"] = \"white\"\n",
    "pplt.rc[\"grid\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743b9b1-90c0-4ac0-89fa-7fdeb6024237",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "data_name = \"spirals\"\n",
    "data_kws = dict()\n",
    "data_size = int(1.00e+06)\n",
    "data_noise = 0.1\n",
    "data_decorr = False\n",
    "data_shuffle = True\n",
    "data_normalize = True\n",
    "seed = 0\n",
    "\n",
    "n_meas = 6\n",
    "max_angle = 180.0\n",
    "meas_bins = 100\n",
    "xmax = 2.75\n",
    "\n",
    "res = 75  # n evaluation points along integration axis\n",
    "n_steps = 10\n",
    "n_iterations = 500\n",
    "alpha_min = 500.0\n",
    "alpha_step = 0.0\n",
    "alpha_mult = 2.0\n",
    "beta = 0.0\n",
    "\n",
    "rtol = 0.25\n",
    "patience = 100\n",
    "\n",
    "vis_size = 100000\n",
    "vis_bins = 75\n",
    "vis_res = 150\n",
    "vis_freq = 100\n",
    "\n",
    "n_flows = 5\n",
    "hidden_units = 64\n",
    "hidden_layers = 3\n",
    "spline_bins = 20\n",
    "\n",
    "targ_scale = 1.0\n",
    "\n",
    "lr = 0.001\n",
    "weight_decay = 1.00e-05\n",
    "\n",
    "cvt = lambda x: x.type(torch.float32).to(device)\n",
    "grab = lambda x: x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4a597-a78a-48e8-b0de-fe4113f5889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "x0 = gen_data(\n",
    "    name=data_name,\n",
    "    size=data_size,\n",
    "    shuffle=data_shuffle,\n",
    "    normalize=data_normalize,\n",
    "    noise=data_noise,\n",
    "    seed=seed,\n",
    "    **data_kws\n",
    ")\n",
    "x0 = cvt(torch.from_numpy(x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e582fb-b0bd-454c-a9bd-dfef9c645afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice = mf.lattice.LinearLattice()\n",
    "lattice = lattice.to(device)\n",
    "\n",
    "angles = np.linspace(0.0, np.radians(max_angle), n_meas, endpoint=False)\n",
    "transfer_matrices = []\n",
    "for angle in angles:\n",
    "    matrix = mf.utils.rotation_matrix(angle)\n",
    "    matrix = cvt(torch.from_numpy(matrix))\n",
    "    transfer_matrices.append(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908c8f1-8ad7-4001-9320-3b21a83f5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = 2 * [(-xmax, xmax)]\n",
    "bin_edges = cvt(torch.linspace(-xmax, xmax, meas_bins + 1))\n",
    "bin_centers = mf.utils.centers_from_edges(bin_edges)\n",
    "\n",
    "diagnostic = mf.diagnostics.Histogram1D(edges=bin_edges, bandwidth=None)\n",
    "diagnostic = diagnostic.to(device)\n",
    "\n",
    "measurements = []\n",
    "for matrix in transfer_matrices:\n",
    "    lattice.set_matrix(matrix)\n",
    "    measurements.append(diagnostic(lattice(x0), kde=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf61ae8-cbea-4851-aa24-a047be6ac4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = zuko.flows.NSF(\n",
    "    features=d, \n",
    "    transforms=n_flows, \n",
    "    bins=spline_bins,\n",
    "    hidden_features=([hidden_units] * hidden_layers),\n",
    "    randperm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c0be9-7ca0-49ef-8793-0daf49f0b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = zuko.distributions.DiagNormal(\n",
    "    loc=cvt(torch.zeros(d)), \n",
    "    scale=cvt(targ_scale * torch.ones(d))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24438225-3ac2-45bb-adb1-e0f2388d2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mf.MENTFlow(\n",
    "    flow=flow,\n",
    "    target=target,\n",
    "    lattice=lattice,\n",
    "    diagnostic=diagnostic,\n",
    "    measurements=measurements,\n",
    "    transfer_matrices=transfer_matrices,\n",
    "    alpha=alpha_min,\n",
    "    beta=beta,\n",
    "    # loss=\"kld\",\n",
    "    loss=\"mae\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbfb01c-3cd1-4a4a-909f-ad4b391ebe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in [\"sart\", \"fbp\"]:\n",
    "    image = utils.reconstruct(measurements, angles, method=method, iterations=10)\n",
    "    x = utils.sample_image(image, edges=(grab(bin_edges), grab(bin_edges)), n=vis_size)\n",
    "    x = cvt(torch.from_numpy(x))\n",
    "\n",
    "    predictions = []\n",
    "    for matrix in transfer_matrices:\n",
    "        lattice.set_matrix(matrix)\n",
    "        predictions.append(diagnostic(lattice(x), kde=False))\n",
    "        \n",
    "    fig, axs = pplt.subplots(ncols=3, xspineloc=\"neither\", yspineloc=\"neither\", space=0.0, share=False)\n",
    "    plotting.plot_cloud(grab(x0)[:vis_size], bins=vis_bins, limits=limits, ax=axs[0])\n",
    "    plotting.plot_cloud(grab(x), bins=vis_bins, limits=limits, ax=axs[1])\n",
    "    plotting.plot_image(image, coords=(2 * [0.5 * (grab(bin_edges)[1:] + grab(bin_edges)[:-1])]), ax=axs[2])                \n",
    "    axs.format(xlim=limits[0], ylim=limits[1])\n",
    "    plt.show()\n",
    "    \n",
    "    axs = plotting.plot_proj(measurements, predictions, edges=grab(bin_edges))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411df485-ccb3-418d-8ee4-137415f22f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_avg_cost = float(\"inf\")\n",
    "stop = False\n",
    "meter = mf.train.RunningAverageMeter(momentum=0.99)\n",
    "\n",
    "for step in range(1, n_steps + 1):\n",
    "    print(\"step={} alpha={:0.4f} beta={}\".format(step, model.alpha, model.beta))\n",
    "    meter.reset()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    for iteration in range(1, n_iterations + 1):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Estimate entropy from samples.\n",
    "        x, log_prob, H = model.sample(1000)\n",
    "\n",
    "        # Predict profiles by integrating density.\n",
    "        predictions = []\n",
    "        for matrix, measurement in zip(transfer_matrices, measurements):\n",
    "            coords = [grab(bin_centers), np.linspace(-xmax, xmax, res)]\n",
    "            x_grid = mf.utils.get_grid_points(coords)\n",
    "            x_grid = cvt(torch.from_numpy(x_grid))\n",
    "\n",
    "            lattice.set_matrix(matrix)\n",
    "            log_prob = flow().log_prob(lattice.inverse(x_grid))\n",
    "            prob = torch.exp(log_prob).reshape([len(c) for c in coords])\n",
    "            prob = prob.reshape([len(c) for c in coords])\n",
    "            prediction = torch.sum(prob, 1)\n",
    "            prediction = prediction / torch.sum(prediction) / (bin_edges[1] - bin_edges[0])\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        C = []\n",
    "        for prediction, measurement in zip(predictions, measurements):\n",
    "            cost = model.loss_func(prediction, measurement)\n",
    "            C.append(cost)\n",
    "\n",
    "        loss = model.loss_function(H, C)\n",
    "        \n",
    "        if not (torch.isinf(loss) or torch.isnan(loss)):\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        cost = float(sum(C) / len(C))\n",
    "        meter.action(cost)\n",
    "    \n",
    "        if iteration > 1 and (iteration % 10 == 0):\n",
    "            message = \"iter={:05.0f} t={:0.2f} loss={:0.3e} H={:0.3e} C={:0.3e} Cavg={:0.3e} alpha={:0.4f}\".format(\n",
    "                iteration, time.time() - t0, float(loss), float(H), float(cost), meter.avg, model.alpha,\n",
    "            )\n",
    "            print(message)\n",
    "    \n",
    "        if iteration > 1 and (iteration % vis_freq == 0):\n",
    "            model.eval()\n",
    "            with torch.no_grad():               \n",
    "                x, _, _ = model.sample(vis_size)\n",
    "                x = cvt(x)\n",
    "\n",
    "                # predictions = model(x, kde=False)\n",
    "\n",
    "                # Predict profiles by integrating density.\n",
    "                predictions = []\n",
    "                for matrix, measurement in zip(transfer_matrices, measurements):\n",
    "                    coords = [grab(bin_centers), np.linspace(-xmax, xmax, res)]\n",
    "                    x_grid = mf.utils.get_grid_points(coords)\n",
    "                    x_grid = cvt(torch.from_numpy(x_grid))\n",
    "        \n",
    "                    lattice.set_matrix(matrix)\n",
    "                    log_prob = flow().log_prob(lattice.inverse(x_grid))\n",
    "                    prob = torch.exp(log_prob).reshape([len(c) for c in coords])\n",
    "                    prob = prob.reshape([len(c) for c in coords])\n",
    "                    prediction = torch.sum(prob, 1)\n",
    "                    prediction = prediction / torch.sum(prediction) / (bin_edges[1] - bin_edges[0])\n",
    "                    predictions.append(prediction)\n",
    "                                \n",
    "                coords = 2 * [torch.linspace(-xmax, xmax, vis_res)]\n",
    "                x_grid = torch.vstack([C.ravel() for C in torch.meshgrid(*coords, indexing=\"ij\")]).T\n",
    "                log_prob = flow().log_prob(x_grid)\n",
    "                log_prob = log_prob.reshape((vis_res, vis_res))\n",
    "        \n",
    "                x = grab(x)\n",
    "                x_true = grab(x0[:vis_size])\n",
    "                prob = grab(torch.exp(log_prob))\n",
    "                \n",
    "                fig, axs = pplt.subplots(ncols=3, xspineloc=\"neither\", yspineloc=\"neither\", space=0.0)\n",
    "                kws = dict()\n",
    "                for ax, _x in zip(axs, [x_true, x]):\n",
    "                    plotting.plot_cloud(_x[:vis_size], bins=vis_bins, limits=limits, ax=ax, **kws)\n",
    "                plotting.plot_image(prob, coords=coords, ax=axs[-1], **kws)\n",
    "                plt.show()\n",
    "    \n",
    "                maxcols = 7\n",
    "                ncols = min(len(measurements), maxcols)\n",
    "                nrows = int(np.ceil(len(measurements) / ncols))\n",
    "                figheight = 1.75 * nrows\n",
    "                figwidth = 1.25 * ncols * 1.75\n",
    "                fig, axs = pplt.subplots(ncols=ncols, nrows=nrows, figheight=figheight, figwidth=figwidth)\n",
    "                kws = dict(lw=1.25)\n",
    "                for j in range(len(measurements)):\n",
    "                    scale = max(grab(measurements[j]))\n",
    "                    axs[j].stairs(grab(measurements[j]) / scale, edges=grab(bin_edges), color=\"black\", **kws)\n",
    "                    axs[j].stairs(grab(predictions[j]) / scale, edges=grab(bin_edges), color=\"red\", **kws)\n",
    "                axs.format(ymax=1.25)\n",
    "                plt.show()\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "        if meter.n_bad > patience:\n",
    "            print(f\"{meter.n_bad} iters without decrease in avg cost: ending step\")\n",
    "            break\n",
    "\n",
    "    if stop:\n",
    "        print(\"Stopping training early.\")\n",
    "        break\n",
    "\n",
    "    model.beta = [model.beta[i] - model.alpha * float(C[i]) for i in range(len(C))]\n",
    "        \n",
    "    if meter.avg < rtol * last_avg_cost:\n",
    "        model.alpha = alpha_mult * model.alpha + alpha_step\n",
    "    else:\n",
    "        # print(\"Relative cost decrease less than rtol: running one more step\")\n",
    "        # stop = True\n",
    "        pass\n",
    "        \n",
    "    last_avg_cost = meter.avg      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4d7be-8e8e-4f08-a2c8-e8f99a2b3ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d6d43-b4ed-4ce8-ad2d-3c25e96d4384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00695a2-fdd8-48e9-a4ca-e797ecb083d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ot-flow",
   "language": "python",
   "name": "ot-flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
